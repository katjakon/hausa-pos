{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tag_english.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUVthg5GTcWw"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install flair\n",
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mmcIYqv5ZZGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the path to where the parallel data file is located on your device/drive\n",
        "DATA_PATH = \"drive/MyDrive/Data/parallel/Tanzil-en-ha.txt\"\n",
        "\n",
        "UNK = \"<unk>\""
      ],
      "metadata": {
        "id": "CApDDXLxZfcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load tagger\n",
        "tagger = SequenceTagger.load(\"flair/upos-english\")"
      ],
      "metadata": {
        "id": "dn3wJHZOo3Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(DATA_PATH) as f:\n",
        "    counter = 0\n",
        "    line_dict = defaultdict(list)\n",
        "    tag_dict = dict()\n",
        "    for line in f:\n",
        "      if counter%1000 == 0:\n",
        "        print(counter)\n",
        "      # Split line at delimiter\n",
        "      line = line.split(\"|||\")\n",
        "      # Only look at line with the right format.\n",
        "      if len(line) == 2:\n",
        "        src, _ = line\n",
        "        words = src.split()\n",
        "        tags = [(UNK, 0) for i in range(len(words))]\n",
        "        sentence = Sentence(src, use_tokenizer=False)  \n",
        "        # Tag words\n",
        "        if src in tag_dict:\n",
        "          tags = tag_dict[src]\n",
        "        else:\n",
        "          tagger.predict(sentence)\n",
        "          tags = [(tags[\"value\"], tags[\"confidence\"]) for tags in sentence.to_dict()[\"all labels\"]]\n",
        "        line_dict[counter] = tags\n",
        "        tag_dict[src] = tags\n",
        "        counter += 1"
      ],
      "metadata": {
        "id": "ZJOBeLuTO-PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the results are written to the given output path."
      ],
      "metadata": {
        "id": "qGVIjPu5PLg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUT = \"OUT/PATH\"\n",
        "\n",
        "with open(OUT, \"w\", encoding=\"utf-8\") as file:\n",
        "  for i in range(len(line_dict)):\n",
        "    tags = line_dict[i]\n",
        "    tag_str = [\"{}-{}\".format(tag, score) for tag, score in tags]\n",
        "    file.write(\"{}\\n\".format(\" \".join(tag_str)))"
      ],
      "metadata": {
        "id": "MWDPFT2CQggD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}